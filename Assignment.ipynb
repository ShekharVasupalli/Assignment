{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "796db80a-68bc-42b6-ad83-31d17d264cc8",
   "metadata": {},
   "source": [
    "Q1) Explain the properties of the F-distribution.\n",
    "\n",
    "Ans) The F-distribution is a continuous probability distribution that arises frequently in the context of statistical tests, particularly ANOVA (Analysis of Variance) and in comparing the variances of two populations. Its main properties are:\n",
    "\n",
    "The F-distribution has the following key properties:\n",
    "\n",
    "Non-negative: Only takes positive values.\n",
    "Right-skewed: Positively skewed, especially with smaller degrees of freedom.\n",
    "Defined by Degrees of Freedom: Has two parameters, d1 (numerator) and d2 (denominator) degrees of freedom.\n",
    "Mean: Exists and is \n",
    "ùëë2 / ùëë2 ‚àí 2 for ùëë2 > 2\n",
    "Variance: Exists for \n",
    "ùëë2 > 4, calculated based on both degrees of freedom.\n",
    "Convergence: As ùëë1 and ùëë2 increase, the distribution becomes more symmetric and approaches a normal shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12abf4ce-a9f1-4e12-b0eb-0285f4b82727",
   "metadata": {},
   "source": [
    "Q2) In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?\n",
    "\n",
    "Ans) The F-distribution is commonly used in statistical tests that involve comparing variances or analyzing multiple group means. Key tests that use the F-distribution include:\n",
    "\n",
    "ANOVA (Analysis of Variance): Used to test whether there are significant differences between the means of three or more groups. The F-distribution is appropriate because ANOVA assesses the ratio of the variance between group means to the variance within groups, which follows an F-distribution if the null hypothesis is true (equal means across groups).\n",
    "\n",
    "Regression Analysis: In testing the overall significance of a multiple regression model, the F-distribution is used to determine if the model explains a significant portion of the variability in the dependent variable. Here, it‚Äôs applied to compare the variance explained by the model (regression sum of squares) to the unexplained variance (error sum of squares).\n",
    "\n",
    "Testing Equality of Variances (Levene‚Äôs Test, Bartlett‚Äôs Test): The F-distribution is used to compare the variances of two or more populations, particularly in Levene‚Äôs and Bartlett‚Äôs tests, which are designed to check the assumption of equal variances in ANOVA.\n",
    "\n",
    "The F-distribution is suitable for these tests because it provides a way to assess the ratio of variances, which aligns with how these tests examine the relative spread of data, either between group means (in ANOVA) or between explained and unexplained variances (in regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e928ba-65a6-4206-9310-a76a64ece886",
   "metadata": {},
   "source": [
    "Q3) What are the key assumptions required for conducting an F-test to compare the variances of two populations?\n",
    "\n",
    "Ans) The key assumptions for conducting an F-test to compare the variances of two populations are:\n",
    "\n",
    "Normality: The data in each population should be normally distributed. The F-test is sensitive to deviations from normality, and non-normal data can lead to inaccurate results.\n",
    "\n",
    "Independence: The samples must be independent, meaning that the data points in one sample do not influence the data points in the other sample. Violations of independence can distort variance estimates.\n",
    "\n",
    "Random Sampling: The samples should be drawn randomly from the populations they represent, ensuring that results are generalizable to those populations.\n",
    "\n",
    "Ratio of Variances: The F-test assumes that the ratio of the sample variances is used as a measure of the population variance ratio. This is meaningful only if the populations themselves are reasonably stable or well-defined.\n",
    "\n",
    "These assumptions help ensure that the F-test results are valid and that any differences found in variances are statistically meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07116d8c-5300-4631-86c1-68951107cdc7",
   "metadata": {},
   "source": [
    "Q4)  What is the purpose of ANOVA, and how does it differ from a t-test?\n",
    "\n",
    "Ans) The purpose of ANOVA (Analysis of Variance) is to determine whether there are statistically significant differences among the means of three or more groups. It compares the variability between group means to the variability within groups to test if at least one group mean is different from the others.\n",
    "\n",
    "Key differences between ANOVA and a t-test are:\n",
    "\n",
    "Number of Groups:\n",
    "\n",
    "t-test: Typically used to compare the means of two groups.\n",
    "ANOVA: Used to compare the means of three or more groups.\n",
    "Type of Analysis:\n",
    "\n",
    "t-test: Directly assesses the difference between two group means.\n",
    "ANOVA: Assesses the overall variance among group means but does not specify which groups differ. Post hoc tests (e.g., Tukey's) are needed if ANOVA finds significant differences to identify which groups differ.\n",
    "Risk of Type I Error:\n",
    "\n",
    "Conducting multiple t-tests to compare multiple groups increases the likelihood of a Type I error (false positive).\n",
    "ANOVA controls the Type I error rate when comparing multiple groups simultaneously, making it more appropriate for studies with multiple group comparisons.\n",
    "In summary, ANOVA is the preferred method for comparing means across three or more groups in one test, while the t-test is suited for direct comparisons between two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0230b6e8-19de-422a-b063-1018ea6253b5",
   "metadata": {},
   "source": [
    "Q5) Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more than two groups.\n",
    "\n",
    "Ans) A one-way ANOVA is preferred over multiple t-tests when comparing more than two groups because it provides a single test to assess whether any of the group means are significantly different. This approach is advantageous in the following ways:\n",
    "\n",
    "Control of Type I Error: Conducting multiple t-tests increases the risk of Type I error (false positive), as each additional test adds to the overall error probability. A one-way ANOVA maintains a single significance level (usually 5%), thereby controlling for Type I error across all group comparisons.\n",
    "\n",
    "Efficiency: With three or more groups, performing a series of pairwise t-tests can be time-consuming and computationally inefficient. A one-way ANOVA simplifies the analysis by evaluating all group means at once.\n",
    "\n",
    "Overall Significance Test: One-way ANOVA tests the null hypothesis that all group means are equal, without specifying which groups differ. If the ANOVA result is significant, post hoc tests can then be used to determine where the differences lie. This step-by-step approach is more systematic than performing multiple t-tests.\n",
    "\n",
    "In short, a one-way ANOVA is the appropriate choice when comparing three or more groups to avoid inflated Type I error, to streamline the analysis, and to obtain an initial test of overall group differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebccce8e-9bfe-4107-bb15-074443726fe7",
   "metadata": {},
   "source": [
    "Q6) Explain how variance is partitioned in ANOVA into between-group variance and within-group variance. How does this partitioning contribute to the calculation of the F-statistic?\n",
    "\n",
    "Ans) nIn ANOVA, the total variance is partitioned into two components: between-group variance and within-group variance. This partitioning allows us to determine if there are significant differences between group means by comparing the variability due to group differences against the variability within each group.\n",
    "\n",
    "1. Between-Group Variance (SSB):\n",
    "This represents the variation in data due to differences between the group means.\n",
    "It is calculated by taking the deviation of each group mean from the overall mean (grand mean) and weighing it by the group size.\n",
    "A large between-group variance suggests that there are significant differences among the group means.\n",
    "\n",
    "3. Within-Group Variance (SSW):\n",
    "This reflects the variation within each group, essentially measuring how much individual data points deviate from their respective group means.\n",
    "It‚Äôs calculated by summing the squared deviations of each data point from its group mean.\n",
    "\n",
    "4. Calculation of the F-Statistic:\n",
    "The F-statistic is calculated by taking the ratio of the mean between-group variance to the mean within-group variance. This is expressed as:\n",
    "F = MSB/MSW\n",
    "\n",
    "‚Äãwhere:\n",
    "MSB = SSB / k‚àí1(Mean Square Between) represents the average variance between groups.\n",
    "MSW = SSW / N‚àík (Mean Square Within) represents the average variance within groups.\n",
    "\n",
    "k is the number of groups, and \n",
    "\n",
    "N is the total number of observations.\n",
    "\n",
    "Contribution to the F-statistic\n",
    "A larger F-statistic value indicates that the between-group variance (signal) is large relative to the within-group variance (noise), suggesting that the group means are not equal.\n",
    "\n",
    "If the F-statistic is significantly high (relative to an F-distribution for the degrees of freedom), we reject the null hypothesis that all group means are equal, concluding that there are significant differences among the groups.ant differences among the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008f2fe-6294-46d7-9ef4-9979d504e7fa",
   "metadata": {},
   "source": [
    "Q7) Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key \n",
    "differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing\n",
    "\n",
    "Ans) The classical (frequentist) and Bayesian approaches to ANOVA differ in how they handle uncertainty, parameter estimation, and hypothesis testing. Here are the key differences:\n",
    "\n",
    "1. Uncertainty\n",
    "Frequentist ANOVA: Treats parameters as fixed values and quantifies uncertainty through p-values, which indicate the probability of observing data as extreme as (or more extreme than) the sample data under the null hypothesis.\n",
    "Bayesian ANOVA: Treats parameters as random variables with probability distributions. Uncertainty is represented as credible intervals, which provide the range within which parameters are likely to fall with a specified probability.\n",
    "2. Parameter Estimation\n",
    "Frequentist ANOVA: Estimates parameters (e.g., group means, variances) using point estimates (e.g., sample means) and assumes a single ‚Äútrue‚Äù value. Parameters are considered fixed and are estimated solely from the observed data.\n",
    "Bayesian ANOVA: Uses prior distributions combined with observed data to produce posterior distributions for parameters. This approach allows for incorporating prior knowledge or beliefs about parameters and produces a range of likely parameter values.\n",
    "3. Hypothesis Testing\n",
    "Frequentist ANOVA: Uses p-values to test the null hypothesis (that all group means are equal) against an alternative hypothesis. Rejecting the null hypothesis is based on a significance level (usually 0.05).\n",
    "Bayesian ANOVA: Often does not involve null hypothesis significance testing in the same way. Instead, it assesses hypotheses by comparing models using metrics like Bayes factors or examining the posterior distributions of the parameters. This allows for direct probability statements about hypotheses, such as the probability that group means differ.?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac114f26-9e58-4741-8334-5700961b9f13",
   "metadata": {},
   "source": [
    "Q8) Question: You have two sets of data representing the incomes of two different professions:\n",
    ". Profession A: [48, 52, 55, 60, 62' \n",
    ". Profession B: [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions'  incomes are equal. What are your conclusions based on the F-test? \n",
    "\n",
    "Task: Use Python to calculate the F-statistic and p-value for the given data.\n",
    "\n",
    "Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison.\n",
    "\n",
    "Ans) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1500f250-b78f-4867-8168-66635d4c180c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.089171974522293, 0.24652429950266966)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "profession_A = np.array([48, 52, 55, 60, 62])\n",
    "profession_B = np.array([45, 50, 55, 52, 47])\n",
    "\n",
    "var_A = np.var(profession_A, ddof=1)\n",
    "var_B = np.var(profession_B, ddof=1)\n",
    "\n",
    "f_statistic = var_A / var_B\n",
    "\n",
    "df_A = len(profession_A) - 1\n",
    "df_B = len(profession_B) - 1\n",
    "\n",
    "p_value = stats.f.sf(f_statistic, df_A, df_B)\n",
    "\n",
    "f_statistic, p_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a934d028-1260-4667-b662-6f7eaa1c5b48",
   "metadata": {},
   "source": [
    "Q9) Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in  average heights between three different regions with the following data: \n",
    ". Region A: [160, 162, 165, 158, 164' \n",
    ". Region B: [172, 175, 170, 168, 174' \n",
    ". Region C: [180, 182, 179, 185, 183' \n",
    ". Task: Write Python code to perform the one-way ANOVA and interpret the results\f",
    " \n",
    ". Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value.\n",
    "\n",
    "Ans) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12f6c7cd-5cb1-49ca-882e-bba451c9f034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67.87330316742101, 2.870664187937026e-07)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "region_A = [160, 162, 165, 158, 164]\n",
    "region_B = [172, 175, 170, 168, 174]\n",
    "region_C = [180, 182, 179, 185, 183]\n",
    "\n",
    "f_statistic, p_value = stats.f_oneway(region_A, region_B, region_C)\n",
    "\n",
    "f_statistic, p_value\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
